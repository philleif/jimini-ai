{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflowjs as tfjs\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.TensorBoard at 0x1c2a7fde48>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=32, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/training-candles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mts</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "      <th>pair</th>\n",
       "      <th>timeframe</th>\n",
       "      <th>upDownThreeMethods</th>\n",
       "      <th>upsideGapTwoCrows</th>\n",
       "      <th>...</th>\n",
       "      <th>minus_dm</th>\n",
       "      <th>plus_di</th>\n",
       "      <th>minus_di</th>\n",
       "      <th>cvi</th>\n",
       "      <th>adx</th>\n",
       "      <th>apo</th>\n",
       "      <th>rocr</th>\n",
       "      <th>percentChange</th>\n",
       "      <th>strategy</th>\n",
       "      <th>strategyCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1526508900000</td>\n",
       "      <td>0.68934</td>\n",
       "      <td>0.68807</td>\n",
       "      <td>0.68964</td>\n",
       "      <td>0.68786</td>\n",
       "      <td>92037.635296</td>\n",
       "      <td>tXRPUSD</td>\n",
       "      <td>15m</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158281</td>\n",
       "      <td>0.541802</td>\n",
       "      <td>0.130054</td>\n",
       "      <td>0.284717</td>\n",
       "      <td>0.305497</td>\n",
       "      <td>0.626824</td>\n",
       "      <td>1.007659</td>\n",
       "      <td>-0.332815</td>\n",
       "      <td>LONG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1526509800000</td>\n",
       "      <td>0.68807</td>\n",
       "      <td>0.69337</td>\n",
       "      <td>0.69654</td>\n",
       "      <td>0.68798</td>\n",
       "      <td>342806.832130</td>\n",
       "      <td>tXRPUSD</td>\n",
       "      <td>15m</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139982</td>\n",
       "      <td>0.691945</td>\n",
       "      <td>0.096433</td>\n",
       "      <td>0.415318</td>\n",
       "      <td>0.363192</td>\n",
       "      <td>0.679183</td>\n",
       "      <td>1.014871</td>\n",
       "      <td>0.764383</td>\n",
       "      <td>SHORT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1526510700000</td>\n",
       "      <td>0.69337</td>\n",
       "      <td>0.69205</td>\n",
       "      <td>0.69345</td>\n",
       "      <td>0.69042</td>\n",
       "      <td>79685.963285</td>\n",
       "      <td>tXRPUSD</td>\n",
       "      <td>15m</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122990</td>\n",
       "      <td>0.654195</td>\n",
       "      <td>0.085807</td>\n",
       "      <td>0.453708</td>\n",
       "      <td>0.416766</td>\n",
       "      <td>0.710954</td>\n",
       "      <td>1.016226</td>\n",
       "      <td>-0.190738</td>\n",
       "      <td>LONG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1526511600000</td>\n",
       "      <td>0.69206</td>\n",
       "      <td>0.69478</td>\n",
       "      <td>0.69667</td>\n",
       "      <td>0.69150</td>\n",
       "      <td>262595.672256</td>\n",
       "      <td>tXRPUSD</td>\n",
       "      <td>15m</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107212</td>\n",
       "      <td>0.704697</td>\n",
       "      <td>0.068685</td>\n",
       "      <td>0.601596</td>\n",
       "      <td>0.474464</td>\n",
       "      <td>0.751934</td>\n",
       "      <td>1.023919</td>\n",
       "      <td>0.392930</td>\n",
       "      <td>SHORT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1526512500000</td>\n",
       "      <td>0.69440</td>\n",
       "      <td>0.69451</td>\n",
       "      <td>0.69656</td>\n",
       "      <td>0.69303</td>\n",
       "      <td>169990.366154</td>\n",
       "      <td>tXRPUSD</td>\n",
       "      <td>15m</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092561</td>\n",
       "      <td>0.659651</td>\n",
       "      <td>0.057741</td>\n",
       "      <td>0.621157</td>\n",
       "      <td>0.528040</td>\n",
       "      <td>0.780616</td>\n",
       "      <td>1.022978</td>\n",
       "      <td>-0.038876</td>\n",
       "      <td>LONG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             mts     open    close     high      low         volume     pair  \\\n",
       "0  1526508900000  0.68934  0.68807  0.68964  0.68786   92037.635296  tXRPUSD   \n",
       "1  1526509800000  0.68807  0.69337  0.69654  0.68798  342806.832130  tXRPUSD   \n",
       "2  1526510700000  0.69337  0.69205  0.69345  0.69042   79685.963285  tXRPUSD   \n",
       "3  1526511600000  0.69206  0.69478  0.69667  0.69150  262595.672256  tXRPUSD   \n",
       "4  1526512500000  0.69440  0.69451  0.69656  0.69303  169990.366154  tXRPUSD   \n",
       "\n",
       "  timeframe  upDownThreeMethods  upsideGapTwoCrows      ...       minus_dm  \\\n",
       "0       15m                   0                  0      ...       0.158281   \n",
       "1       15m                   0                  0      ...       0.139982   \n",
       "2       15m                   0                  0      ...       0.122990   \n",
       "3       15m                   0                  0      ...       0.107212   \n",
       "4       15m                   0                  0      ...       0.092561   \n",
       "\n",
       "    plus_di  minus_di       cvi       adx       apo      rocr  percentChange  \\\n",
       "0  0.541802  0.130054  0.284717  0.305497  0.626824  1.007659      -0.332815   \n",
       "1  0.691945  0.096433  0.415318  0.363192  0.679183  1.014871       0.764383   \n",
       "2  0.654195  0.085807  0.453708  0.416766  0.710954  1.016226      -0.190738   \n",
       "3  0.704697  0.068685  0.601596  0.474464  0.751934  1.023919       0.392930   \n",
       "4  0.659651  0.057741  0.621157  0.528040  0.780616  1.022978      -0.038876   \n",
       "\n",
       "   strategy  strategyCode  \n",
       "0      LONG             1  \n",
       "1     SHORT             0  \n",
       "2      LONG             1  \n",
       "3     SHORT             0  \n",
       "4      LONG             1  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer=\"adam\", init_mode=\"uniform\", activation=\"sigmoid\"):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(48, kernel_initializer=init_mode, input_shape=(46,), activation=activation))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(24, kernel_initializer=init_mode, activation=activation))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(12, kernel_initializer=init_mode, activation=activation))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, kernel_initializer=init_mode, activation=\"sigmoid\"))\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\",\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"adx\", \"cci\", \"rocr\", \"hikkake\", \"harami\", \"closingMarubozu\", \n",
    "        \"onNeck\", \"longLineCandle\", \"hikkakeModified\", \"apo\", \"cmo\", \"adx\",\n",
    "        \"cvi\", \"plus_dm\", \"minus_dm\", \"plus_di\", \"minus_di\", \"dpo\", \"kvo\",\n",
    "        \"fosc\", \"fisher\", \"fisher_signal\", \"dx\", \"linregslope\", \"macd\", \"macd_signal\", \n",
    "        \"macd_histogram\", \"mfi\", \"mom\", \"obv\", \"ppo\", \"pvi\", \"rsi\", \"stoch_k\", \"stoch_d\",\n",
    "        \"atr\", \"trix\", \"ultosc\", \"vosc\", \"willr\", \"cmo\", \"cci\", \"adosc\", \"adxr\", \"ao\",\n",
    "        \"aroonosc\"\n",
    "       ]].values\n",
    "\n",
    "y = df[\"strategyCode\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "batch_size = [128]\n",
    "epochs = [100]\n",
    "optimizer = ['Adadelta', 'Adam']\n",
    "init_mode = ['normal', 'uniform']\n",
    "activation = ['relu', 'softplus', 'sigmoid']\n",
    "\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs, optimizer=optimizer, init_mode=init_mode, activation=activation)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.556526 using {'activation': 'softplus', 'batch_size': 128, 'epochs': 100, 'init_mode': 'normal', 'optimizer': 'Adam'}\n",
      "0.537538 (0.006668) with: {'activation': 'relu', 'batch_size': 128, 'epochs': 100, 'init_mode': 'normal', 'optimizer': 'Adadelta'}\n",
      "0.537320 (0.011068) with: {'activation': 'relu', 'batch_size': 128, 'epochs': 100, 'init_mode': 'normal', 'optimizer': 'Adam'}\n",
      "0.539284 (0.002561) with: {'activation': 'relu', 'batch_size': 128, 'epochs': 100, 'init_mode': 'uniform', 'optimizer': 'Adadelta'}\n",
      "0.551506 (0.005115) with: {'activation': 'relu', 'batch_size': 128, 'epochs': 100, 'init_mode': 'uniform', 'optimizer': 'Adam'}\n",
      "0.542994 (0.011447) with: {'activation': 'softplus', 'batch_size': 128, 'epochs': 100, 'init_mode': 'normal', 'optimizer': 'Adadelta'}\n",
      "0.556526 (0.014336) with: {'activation': 'softplus', 'batch_size': 128, 'epochs': 100, 'init_mode': 'normal', 'optimizer': 'Adam'}\n",
      "0.545832 (0.004886) with: {'activation': 'softplus', 'batch_size': 128, 'epochs': 100, 'init_mode': 'uniform', 'optimizer': 'Adadelta'}\n",
      "0.536883 (0.003789) with: {'activation': 'softplus', 'batch_size': 128, 'epochs': 100, 'init_mode': 'uniform', 'optimizer': 'Adam'}\n",
      "0.499782 (0.006796) with: {'activation': 'sigmoid', 'batch_size': 128, 'epochs': 100, 'init_mode': 'normal', 'optimizer': 'Adadelta'}\n",
      "0.547796 (0.004717) with: {'activation': 'sigmoid', 'batch_size': 128, 'epochs': 100, 'init_mode': 'normal', 'optimizer': 'Adam'}\n",
      "0.496290 (0.002705) with: {'activation': 'sigmoid', 'batch_size': 128, 'epochs': 100, 'init_mode': 'uniform', 'optimizer': 'Adadelta'}\n",
      "0.548450 (0.004423) with: {'activation': 'sigmoid', 'batch_size': 128, 'epochs': 100, 'init_mode': 'uniform', 'optimizer': 'Adam'}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4582/4582 [==============================] - 9s 2ms/step - loss: 0.6936 - acc: 0.4980\n",
      "Epoch 2/100\n",
      "4582/4582 [==============================] - 0s 34us/step - loss: 0.6927 - acc: 0.5225\n",
      "Epoch 3/100\n",
      "4582/4582 [==============================] - 0s 35us/step - loss: 0.6928 - acc: 0.5120\n",
      "Epoch 4/100\n",
      "4582/4582 [==============================] - 0s 33us/step - loss: 0.6922 - acc: 0.5131\n",
      "Epoch 5/100\n",
      "4582/4582 [==============================] - 0s 32us/step - loss: 0.6925 - acc: 0.5085\n",
      "Epoch 6/100\n",
      "4582/4582 [==============================] - 0s 32us/step - loss: 0.6932 - acc: 0.5146\n",
      "Epoch 7/100\n",
      "4582/4582 [==============================] - 0s 32us/step - loss: 0.6918 - acc: 0.5214\n",
      "Epoch 8/100\n",
      "4582/4582 [==============================] - 0s 37us/step - loss: 0.6916 - acc: 0.5249\n",
      "Epoch 9/100\n",
      "4582/4582 [==============================] - 0s 33us/step - loss: 0.6911 - acc: 0.5323\n",
      "Epoch 10/100\n",
      "4582/4582 [==============================] - 0s 32us/step - loss: 0.6904 - acc: 0.5310\n",
      "Epoch 11/100\n",
      "4582/4582 [==============================] - 0s 34us/step - loss: 0.6904 - acc: 0.5275\n",
      "Epoch 12/100\n",
      "4582/4582 [==============================] - 0s 33us/step - loss: 0.6905 - acc: 0.5264\n",
      "Epoch 13/100\n",
      "4582/4582 [==============================] - 0s 39us/step - loss: 0.6894 - acc: 0.5334\n",
      "Epoch 14/100\n",
      "4582/4582 [==============================] - 0s 39us/step - loss: 0.6886 - acc: 0.5404\n",
      "Epoch 15/100\n",
      "4582/4582 [==============================] - 0s 40us/step - loss: 0.6877 - acc: 0.5412\n",
      "Epoch 16/100\n",
      "4582/4582 [==============================] - 0s 36us/step - loss: 0.6869 - acc: 0.5406\n",
      "Epoch 17/100\n",
      "4582/4582 [==============================] - 0s 37us/step - loss: 0.6869 - acc: 0.5397\n",
      "Epoch 18/100\n",
      "4582/4582 [==============================] - 0s 37us/step - loss: 0.6864 - acc: 0.5432\n",
      "Epoch 19/100\n",
      "4582/4582 [==============================] - 0s 34us/step - loss: 0.6857 - acc: 0.5406\n",
      "Epoch 20/100\n",
      "4582/4582 [==============================] - 0s 34us/step - loss: 0.6861 - acc: 0.5450\n",
      "Epoch 21/100\n",
      "4582/4582 [==============================] - 0s 34us/step - loss: 0.6877 - acc: 0.5362\n",
      "Epoch 22/100\n",
      "4582/4582 [==============================] - 0s 35us/step - loss: 0.6867 - acc: 0.5419\n",
      "Epoch 23/100\n",
      "4582/4582 [==============================] - 0s 36us/step - loss: 0.6841 - acc: 0.5511\n",
      "Epoch 24/100\n",
      "4582/4582 [==============================] - 0s 33us/step - loss: 0.6854 - acc: 0.5522\n",
      "Epoch 25/100\n",
      "4582/4582 [==============================] - 0s 36us/step - loss: 0.6835 - acc: 0.5589\n",
      "Epoch 26/100\n",
      "4582/4582 [==============================] - 0s 34us/step - loss: 0.6827 - acc: 0.5524\n",
      "Epoch 27/100\n",
      "4582/4582 [==============================] - 0s 39us/step - loss: 0.6861 - acc: 0.5519\n",
      "Epoch 28/100\n",
      "4582/4582 [==============================] - 0s 38us/step - loss: 0.6839 - acc: 0.5509\n",
      "Epoch 29/100\n",
      "4582/4582 [==============================] - 0s 33us/step - loss: 0.6840 - acc: 0.5537\n",
      "Epoch 30/100\n",
      "4582/4582 [==============================] - 0s 36us/step - loss: 0.6842 - acc: 0.5548\n",
      "Epoch 31/100\n",
      "4582/4582 [==============================] - 0s 34us/step - loss: 0.6828 - acc: 0.5543\n",
      "Epoch 32/100\n",
      "4582/4582 [==============================] - 0s 35us/step - loss: 0.6827 - acc: 0.5426\n",
      "Epoch 33/100\n",
      "4582/4582 [==============================] - 0s 37us/step - loss: 0.6825 - acc: 0.5491\n",
      "Epoch 34/100\n",
      "4582/4582 [==============================] - 0s 37us/step - loss: 0.6815 - acc: 0.5506\n",
      "Epoch 35/100\n",
      "4582/4582 [==============================] - 0s 42us/step - loss: 0.6816 - acc: 0.5637\n",
      "Epoch 36/100\n",
      "4582/4582 [==============================] - 0s 47us/step - loss: 0.6811 - acc: 0.5572\n",
      "Epoch 37/100\n",
      "4582/4582 [==============================] - 0s 39us/step - loss: 0.6807 - acc: 0.5613\n",
      "Epoch 38/100\n",
      "4582/4582 [==============================] - 0s 35us/step - loss: 0.6808 - acc: 0.5600\n",
      "Epoch 39/100\n",
      "4582/4582 [==============================] - 0s 37us/step - loss: 0.6792 - acc: 0.5591\n",
      "Epoch 40/100\n",
      "4582/4582 [==============================] - 0s 32us/step - loss: 0.6803 - acc: 0.5519\n",
      "Epoch 41/100\n",
      "4582/4582 [==============================] - 0s 36us/step - loss: 0.6794 - acc: 0.5615\n",
      "Epoch 42/100\n",
      "4582/4582 [==============================] - 0s 35us/step - loss: 0.6817 - acc: 0.5539\n",
      "Epoch 43/100\n",
      "4582/4582 [==============================] - 0s 37us/step - loss: 0.6786 - acc: 0.5620\n",
      "Epoch 44/100\n",
      "4582/4582 [==============================] - 0s 31us/step - loss: 0.6756 - acc: 0.5639\n",
      "Epoch 45/100\n",
      "4582/4582 [==============================] - 0s 37us/step - loss: 0.6782 - acc: 0.5615\n",
      "Epoch 46/100\n",
      "4582/4582 [==============================] - 0s 37us/step - loss: 0.6779 - acc: 0.5661\n",
      "Epoch 47/100\n",
      "4582/4582 [==============================] - 0s 39us/step - loss: 0.6771 - acc: 0.5674\n",
      "Epoch 48/100\n",
      "4582/4582 [==============================] - 0s 38us/step - loss: 0.6759 - acc: 0.5690\n",
      "Epoch 49/100\n",
      "4582/4582 [==============================] - 0s 38us/step - loss: 0.6761 - acc: 0.5683\n",
      "Epoch 50/100\n",
      "4582/4582 [==============================] - 0s 39us/step - loss: 0.6768 - acc: 0.5637\n",
      "Epoch 51/100\n",
      "4582/4582 [==============================] - 0s 37us/step - loss: 0.6762 - acc: 0.5620\n",
      "Epoch 52/100\n",
      "4582/4582 [==============================] - 0s 40us/step - loss: 0.6754 - acc: 0.5729\n",
      "Epoch 53/100\n",
      "4582/4582 [==============================] - 0s 38us/step - loss: 0.6712 - acc: 0.5790\n",
      "Epoch 54/100\n",
      "4582/4582 [==============================] - 0s 38us/step - loss: 0.6720 - acc: 0.5784\n",
      "Epoch 55/100\n",
      "4582/4582 [==============================] - 0s 36us/step - loss: 0.6730 - acc: 0.5779\n",
      "Epoch 56/100\n",
      "4582/4582 [==============================] - 0s 38us/step - loss: 0.6732 - acc: 0.5668\n",
      "Epoch 57/100\n",
      "4582/4582 [==============================] - 0s 38us/step - loss: 0.6763 - acc: 0.5705\n",
      "Epoch 58/100\n",
      "4582/4582 [==============================] - 0s 35us/step - loss: 0.6733 - acc: 0.5722\n",
      "Epoch 59/100\n",
      "4582/4582 [==============================] - 0s 38us/step - loss: 0.6739 - acc: 0.5718\n",
      "Epoch 60/100\n",
      "4582/4582 [==============================] - 0s 38us/step - loss: 0.6704 - acc: 0.5720\n",
      "Epoch 61/100\n",
      "4582/4582 [==============================] - 0s 39us/step - loss: 0.6729 - acc: 0.5716\n",
      "Epoch 62/100\n",
      "4582/4582 [==============================] - 0s 37us/step - loss: 0.6701 - acc: 0.5823\n",
      "Epoch 63/100\n",
      "4582/4582 [==============================] - 0s 31us/step - loss: 0.6725 - acc: 0.5770\n",
      "Epoch 64/100\n",
      "4582/4582 [==============================] - 0s 34us/step - loss: 0.6722 - acc: 0.5733\n",
      "Epoch 65/100\n",
      "4582/4582 [==============================] - 0s 30us/step - loss: 0.6689 - acc: 0.5805\n",
      "Epoch 66/100\n",
      "4582/4582 [==============================] - 0s 30us/step - loss: 0.6695 - acc: 0.5827\n",
      "Epoch 67/100\n",
      "4582/4582 [==============================] - 0s 38us/step - loss: 0.6683 - acc: 0.5816\n",
      "Epoch 68/100\n",
      "4582/4582 [==============================] - 0s 39us/step - loss: 0.6679 - acc: 0.5851\n",
      "Epoch 69/100\n",
      "4582/4582 [==============================] - 0s 34us/step - loss: 0.6684 - acc: 0.5825\n",
      "Epoch 70/100\n",
      "4582/4582 [==============================] - 0s 31us/step - loss: 0.6668 - acc: 0.5784\n",
      "Epoch 71/100\n",
      "4582/4582 [==============================] - 0s 31us/step - loss: 0.6659 - acc: 0.5904\n",
      "Epoch 72/100\n",
      "4582/4582 [==============================] - 0s 32us/step - loss: 0.6694 - acc: 0.5718\n",
      "Epoch 73/100\n",
      "4582/4582 [==============================] - 0s 41us/step - loss: 0.6643 - acc: 0.5958\n",
      "Epoch 74/100\n",
      "4582/4582 [==============================] - 0s 33us/step - loss: 0.6667 - acc: 0.5762\n",
      "Epoch 75/100\n",
      "4582/4582 [==============================] - 0s 33us/step - loss: 0.6680 - acc: 0.5764\n",
      "Epoch 76/100\n",
      "4582/4582 [==============================] - 0s 30us/step - loss: 0.6650 - acc: 0.5910\n",
      "Epoch 77/100\n",
      "4582/4582 [==============================] - 0s 31us/step - loss: 0.6661 - acc: 0.5890\n",
      "Epoch 78/100\n",
      "4582/4582 [==============================] - 0s 31us/step - loss: 0.6628 - acc: 0.5893\n",
      "Epoch 79/100\n",
      "4582/4582 [==============================] - 0s 30us/step - loss: 0.6645 - acc: 0.5895\n",
      "Epoch 80/100\n",
      "4582/4582 [==============================] - 0s 33us/step - loss: 0.6680 - acc: 0.5797\n",
      "Epoch 81/100\n",
      "4582/4582 [==============================] - 0s 33us/step - loss: 0.6635 - acc: 0.5880\n",
      "Epoch 82/100\n",
      "4582/4582 [==============================] - 0s 42us/step - loss: 0.6617 - acc: 0.5899\n",
      "Epoch 83/100\n",
      "4582/4582 [==============================] - 0s 33us/step - loss: 0.6621 - acc: 0.5853\n",
      "Epoch 84/100\n",
      "4582/4582 [==============================] - 0s 32us/step - loss: 0.6628 - acc: 0.5834\n",
      "Epoch 85/100\n",
      "4582/4582 [==============================] - 0s 32us/step - loss: 0.6608 - acc: 0.5899\n",
      "Epoch 86/100\n",
      "4582/4582 [==============================] - 0s 30us/step - loss: 0.6585 - acc: 0.5877\n",
      "Epoch 87/100\n",
      "4582/4582 [==============================] - 0s 30us/step - loss: 0.6623 - acc: 0.5862\n",
      "Epoch 88/100\n",
      "4582/4582 [==============================] - 0s 33us/step - loss: 0.6640 - acc: 0.5849\n",
      "Epoch 89/100\n",
      "4582/4582 [==============================] - 0s 29us/step - loss: 0.6651 - acc: 0.5753\n",
      "Epoch 90/100\n",
      "4582/4582 [==============================] - 0s 32us/step - loss: 0.6653 - acc: 0.5906\n",
      "Epoch 91/100\n",
      "4582/4582 [==============================] - 0s 30us/step - loss: 0.6617 - acc: 0.5880\n",
      "Epoch 92/100\n",
      "4582/4582 [==============================] - 0s 32us/step - loss: 0.6549 - acc: 0.5986\n",
      "Epoch 93/100\n",
      "4582/4582 [==============================] - 0s 32us/step - loss: 0.6544 - acc: 0.6008\n",
      "Epoch 94/100\n",
      "4582/4582 [==============================] - 0s 30us/step - loss: 0.6590 - acc: 0.5976\n",
      "Epoch 95/100\n",
      "4582/4582 [==============================] - 0s 31us/step - loss: 0.6575 - acc: 0.5914\n",
      "Epoch 96/100\n",
      "4582/4582 [==============================] - 0s 31us/step - loss: 0.6576 - acc: 0.5960\n",
      "Epoch 97/100\n",
      "4582/4582 [==============================] - 0s 33us/step - loss: 0.6596 - acc: 0.5866\n",
      "Epoch 98/100\n",
      "4582/4582 [==============================] - 0s 30us/step - loss: 0.6614 - acc: 0.5934\n",
      "Epoch 99/100\n",
      "4582/4582 [==============================] - 0s 30us/step - loss: 0.6619 - acc: 0.5952\n",
      "Epoch 100/100\n",
      "4582/4582 [==============================] - 0s 31us/step - loss: 0.6561 - acc: 0.6048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ca099cbe0>"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_model = create_model(optimizer=\"Adam\", init_mode=\"normal\", activation=\"softplus\")\n",
    "\n",
    "#y_labels = to_categorical(y_train, num_classes=2)\n",
    "\n",
    "optimal_model.fit(X_train, y_train, epochs=100, batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 7s 7ms/step\n",
      "[0.7050487995147705, 0.5287865400314331]\n"
     ]
    }
   ],
   "source": [
    "#y_test_labels = to_categorical(y_test, num_classes=2)\n",
    "evaluation = optimal_model.evaluate(x=X_test, y=y_test, steps=1000)\n",
    "optimal_model.metrics_names\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfjs.converters.save_keras_model(optimal_model, \"../public/model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
